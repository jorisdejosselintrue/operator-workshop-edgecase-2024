---
# tasks file for Bar
- name: start the bar
  kubernetes.core.k8s:
    definition:
      kind: Deployment
      apiVersion: apps/v1
      metadata:
        name: '{{ ansible_operator_meta.name }}-bar'
        namespace: '{{ ansible_operator_meta.namespace }}'
      spec:
        replicas: "{{ size }}"
        selector:
          matchLabels:
            app: bar
        template:
          metadata:
            labels:
              app: bar
          spec:
            containers:
            - name: bar
              image: "{{ image | default('docker.io/jorisjosselin/waiter-operator-site:latest') }}"
              imagePullPolicy: IfNotPresent
              ports:
                - containerPort: 5000
              env:
              # Define the environment variable
              - name: DRINKS
                valueFrom:
                  configMapKeyRef:
                    # The ConfigMap containing the value you want to assign to SPECIAL_LEVEL_KEY
                    name: '{{ ansible_operator_meta.name }}-bar'
                    # Specify the key associated with the value
                    key: drinks

- name: Create configmap using server side apply
  kubernetes.core.k8s:
    namespace: '{{ ansible_operator_meta.namespace }}'
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: '{{ ansible_operator_meta.name }}-bar'
      data:
        drinks: |
            {{ drinks | to_json }}
    server_side_apply:
      field_manager: ansible
  notify:
    - Restart deployment

- name: Expose Flask port with ClusterIP
  kubernetes.core.k8s:
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: '{{ ansible_operator_meta.name }}-bar'
        namespace: '{{ ansible_operator_meta.namespace }}'
      spec:
        type: NodePort
        selector:
          app: bar
        ports:
          - port: 5000
            protocol: TCP
            targetPort: 5000
            nodePort: 30007

- name: Defaults huh
  debug:
    msg: "The value is {{ stopitjona | default('present') }}"

- name: Add the Jona helper
  kubernetes.core.k8s:
    state: "{{ stopitjona | default('present') }}"
    definition:
      apiVersion: batch/v1
      kind: CronJob
      metadata:
        name: "{{ ansible_operator_meta.name }}-jona-helper"
        namespace: '{{ ansible_operator_meta.namespace }}'
      spec:
        schedule: "*/1 * * * *"
        jobTemplate:
          spec:
            template:
              spec:
                serviceAccountName: waiter-operator-controller-manager
                containers:
                - name: kubectl-patch
                  image: bitnami/kubectl:latest
                  command:
                  - /bin/bash
                  - -c
                  - |
                    drinks_number=$((( $(kubectl get Bar bestbarintown -o=jsonpath="{.spec.drinks.barman.amount_of_drinks_drunken}") + 2 ))); echo ${drinks_number};kubectl patch Bar bestbarintown --type='merge' -p '{"spec": {"drinks": {"barman": {"amount_of_drinks_drunken": '${drinks_number}' } } } }'
                restartPolicy: OnFailure


- name: Check service status
  ansible.builtin.uri:
    url: "http://{{ ansible_operator_meta.name }}-bar.{{ ansible_operator_meta.namespace }}:5000/"
    method: GET
  register: service_status
  failed_when: false

- name: Debug - Show HTTP status code
  debug:
    msg: "HTTP Status Code: {{ service_status.status }} on url http://{{ ansible_operator_meta.name }}-bar.{{ ansible_operator_meta.namespace }}:5000/"

- name: Trigger handler if service status is not 200
  command: "true"
  notify: Sober up the barman
  when: service_status.status != 200
